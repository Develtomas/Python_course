{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Develtomas/Python_course/blob/main/mt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto",
        "id": "9Ytab29nhizg"
      },
      "outputs": [],
      "source": [
        "df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"hdfs:///user/spark/covid/cov.csv\")\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkbhEOjhizk"
      },
      "source": [
        "### Task1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto",
        "id": "0CICGn6Ehizl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "df.select(\"iso_code\", \"location\", (col(\"total_cases_per_million\")/10000).alias(\"%\")).where(col(\"date\")==\"2021-03-31\").sort(col(\"%\").desc()).show(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "+--------+-------------+------------------+\n",
        "|iso_code|     location|                 %|\n",
        "+--------+-------------+------------------+\n",
        "|     AND|      Andorra|        15.5439073|\n",
        "|     MNE|   Montenegro|14.523725399999998|\n",
        "|     CZE|      Czechia|        14.3088484|\n",
        "|     SMR|   San Marino|        13.9371796|\n",
        "|     SVN|     Slovenia|10.370805800000001|\n",
        "|     LUX|   Luxembourg|         9.8473424|\n",
        "|     ISR|       Israel|          9.625106|\n",
        "|     USA|United States|          9.203011|\n",
        "|     SRB|       Serbia|         8.8263286|\n",
        "|     BHR|      Bahrain|         8.4888601|\n",
        "|     PAN|       Panama|         8.2287391|\n",
        "|     PRT|     Portugal|         8.0586997|\n",
        "|     EST|      Estonia|         8.0226816|\n",
        "|     SWE|       Sweden|         7.9697443|\n",
        "|     LTU|    Lithuania|         7.9388647|\n",
        "+--------+-------------+------------------+\n",
        "only showing top 15 rows\n",
        "```"
      ],
      "metadata": {
        "id": "Z879RZoQhv9S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_wEd4uJhizm"
      },
      "source": [
        "###Task2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto",
        "id": "FypcU8U1hizm"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "df.where((to_date(col(\"date\")) >= \"2021-03-29\") & (to_date(col(\"date\")) <= \"2021-03-31\"))\\\n",
        "    .withColumn(\"max_cases\", max(col(\"new_cases\")).over(Window.partitionBy(\"location\")))\\\n",
        "    .select(\"date\", \"location\", \"new_cases\")\\\n",
        "    .where(col(\"max_cases\") == col(\"new_cases\"))\\\n",
        "    .where(~col(\"location\").isin([\"World\", \"Europe\", \"European Union\", \"Asia\", \"South America\", \"North America\"]))\\\n",
        "    .sort(col(\"max_cases\").desc()).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "+-------------------+-------------+---------+\n",
        "|               date|     location|new_cases|\n",
        "+-------------------+-------------+---------+\n",
        "|2021-03-31 00:00:00|       Brazil|  90638.0|\n",
        "|2021-03-31 00:00:00|        India|  72330.0|\n",
        "|2021-03-29 00:00:00|United States|  69429.0|\n",
        "|2021-03-31 00:00:00|       France|  59054.0|\n",
        "|2021-03-31 00:00:00|       Turkey|  39302.0|\n",
        "|2021-03-31 00:00:00|       Poland|  32891.0|\n",
        "|2021-03-31 00:00:00|      Germany|  25014.0|\n",
        "|2021-03-31 00:00:00|        Italy|  23887.0|\n",
        "|2021-03-30 00:00:00|       Sweden|  16427.0|\n",
        "|2021-03-31 00:00:00|    Argentina|  16056.0|\n",
        "+-------------------+-------------+---------+\n",
        "only showing top 10 rows\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bZhM0QE4j-i8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx6yox__hizn"
      },
      "source": [
        "### Task3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto",
        "id": "ul1BZs64hizn"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "df.where((to_date(col(\"date\")) >= \"2021-03-28\") & (to_date(col(\"date\")) <= \"2021-03-31\") & (col(\"location\") == \"Russia\"))\\\n",
        "    .withColumn(\"yesterday_cases\", lag(\"new_cases\").over(Window.orderBy(\"date\")))\\\n",
        "    .select(\"date\", \"yesterday_cases\", \"new_cases\", (col(\"new_cases\")-col(\"yesterday_cases\")).alias(\"delta\"))\\\n",
        "    .where((to_date(col(\"date\")) > \"2021-03-28\"))\\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "+-------------------+---------------+---------+------+\n",
        "|               date|yesterday_cases|new_cases| delta|\n",
        "+-------------------+---------------+---------+------+\n",
        "|2021-03-29 00:00:00|         8979.0|   8589.0|-390.0|\n",
        "|2021-03-30 00:00:00|         8589.0|   8162.0|-427.0|\n",
        "|2021-03-31 00:00:00|         8162.0|   8156.0|  -6.0|\n",
        "+-------------------+---------------+---------+------+\n",
        "```"
      ],
      "metadata": {
        "id": "aYl3eHMJkQHk"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Spark 2.0.0",
      "language": "python",
      "name": "spark2"
    },
    "language_info": {
      "codemirror_mode": "text/python",
      "file_extension": ".py",
      "mimetype": "text/python",
      "name": "scala",
      "pygments_lexer": "python",
      "version": "3.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}